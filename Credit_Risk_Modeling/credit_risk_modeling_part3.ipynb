{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Gini-measure of the root node is given below\n",
    "gini_root <- 2 * 89 / 500 * 411 / 500\n",
    "\n",
    "# Compute the Gini measure for the left leaf node\n",
    "gini_ll <- 2 * (401/446) * (45/446)\n",
    "\n",
    "# Compute the Gini measure for the right leaf node\n",
    "gini_rl <- 2 * 10/54 * 44/54\n",
    "\n",
    "# Compute the gain\n",
    "gain <- gini_root - 446 / 500 * gini_ll - 54 / 500 * gini_rl\n",
    "\n",
    "# compare the gain-column in small_tree$splits with our computed gain, multiplied by 500, and assure they are the same\n",
    "small_tree$splits\n",
    "improve <- gain * 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load package rpart in your workspace.\n",
    "library(rpart)\n",
    "\n",
    "# Change the code provided in the video such that a decision tree is constructed using the undersampled training set. Include rpart.control to relax the complexity parameter to 0.001.\n",
    "tree_undersample <- rpart(loan_status ~ ., method = \"class\",\n",
    "                          data =  undersampled_training_set, control = rpart.control(cp = 0.001))\n",
    "\n",
    "# Plot the decision tree\n",
    "plot(tree_undersample,uniform=T)\n",
    "\n",
    "# Add labels to the decision tree\n",
    "text(tree_undersample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the code below such that a tree is constructed with adjusted prior probabilities.\n",
    "tree_prior <- rpart(loan_status ~ ., method = \"class\",\n",
    "                    data = training_set,control = rpart.control(cp = 0.001),parms = list(prior=c(0.7, 0.3)))\n",
    "\n",
    "# Plot the decision tree\n",
    "plot(tree_prior,uniform=T)\n",
    "\n",
    "# Add labels to the decision tree\n",
    "text(tree_prior)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the code below such that a decision tree is constructed using a loss matrix penalizing 10 times more heavily for misclassified defaults.\n",
    "tree_loss_matrix <- rpart(loan_status ~ ., method = \"class\",\n",
    "                          data =  training_set,control = rpart.control(cp = 0.001),parms = list(loss = matrix(c(0, 10, 1, 0), ncol=2)))\n",
    "\n",
    "\n",
    "# Plot the decision tree\n",
    "plot(tree_loss_matrix,uniform=T)\n",
    "\n",
    "# Add labels to the decision tree\n",
    "text(tree_loss_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree_prior is loaded in your workspace\n",
    "\n",
    "# Plot the cross-validated error rate as a function of the complexity parameter\n",
    "plotcp(tree_prior)\n",
    "\n",
    "# Use printcp() to identify for which complexity parameter the cross-validated error rate is minimized.\n",
    "printcp(tree_prior)\n",
    "\n",
    "# Create an index for of the row with the minimum xerror\n",
    "index <- which.min(tree_prior$cptable[ , \"xerror\"])\n",
    "\n",
    "# Create tree_min\n",
    "tree_min <- tree_prior$cptable[index, \"CP\"]\n",
    "\n",
    "#  Prune the tree using tree_min\n",
    "ptree_prior <- prune(tree_prior, cp = tree_min)\n",
    "\n",
    "# Use prp() to plot the pruned tree\n",
    "prp(ptree_prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a seed and run the code to construct the tree with the loss matrix again\n",
    "set.seed(345)\n",
    "tree_loss_matrix  <- rpart(loan_status ~ ., method = \"class\", data = training_set,\n",
    "                           parms = list(loss=matrix(c(0, 10, 1, 0), ncol = 2)),\n",
    "                           control = rpart.control(cp = 0.001))\n",
    "\n",
    "# Plot the cross-validated error rate as a function of the complexity parameter\n",
    "plotcp(tree_loss_matrix)\n",
    "\n",
    "# Prune the tree using cp = 0.0012788\n",
    "ptree_loss_matrix<-prune(tree_loss_matrix,cp=0.0012788)\n",
    "\n",
    "# Use prp() and argument extra = 1 to plot the pruned tree\n",
    "prp(ptree_loss_matrix,extra=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a seed and run the code to obtain a tree using weights, minsplit and minbucket\n",
    "set.seed(345)\n",
    "tree_weights <- rpart(loan_status ~ ., method = \"class\",\n",
    "                      data = training_set,\n",
    "                      control = rpart.control(minsplit = 5, minbucket = 2, cp = 0.001),weights=case_weights)\n",
    "\n",
    "# Plot the cross-validated error rate for a changing cp\n",
    "plotcp(tree_weights)\n",
    "\n",
    "# Create an index for of the row with the minimum xerror\n",
    "index <- which.min(tree_weights$cp[ , \"xerror\"])\n",
    "\n",
    "# Create tree_min\n",
    "tree_min <- tree_weights$cp[index, \"CP\"]\n",
    "\n",
    "# Prune the tree using tree_min\n",
    "ptree_weights<-prune(tree_weights,cp=tree_min)\n",
    "\n",
    "# Plot the pruned tree using the rpart.plot()-package\n",
    "prp(ptree_weights,extra=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions for each of the pruned trees using the test set.\n",
    "pred_undersample <- predict(ptree_undersample, newdata = test_set,  type = \"class\")\n",
    "pred_prior <- predict(ptree_prior, newdata = test_set,  type = \"class\")\n",
    "pred_loss_matrix <- predict(ptree_loss_matrix, newdata = test_set,  type = \"class\")\n",
    "pred_weights <- predict(ptree_weights, newdata = test_set,  type = \"class\")\n",
    "\n",
    "# construct confusion matrices using the predictions.\n",
    "confmat_undersample <- table(test_set$loan_status, pred_undersample)\n",
    "confmat_prior <- table(test_set$loan_status,pred_prior)\n",
    "confmat_loss_matrix <- table(test_set$loan_status,pred_loss_matrix)\n",
    "confmat_weights <- table(test_set$loan_status,pred_weights)\n",
    "\n",
    "# Compute the accuracies\n",
    "acc_undersample <- sum(diag(confmat_undersample)) / nrow(test_set)\n",
    "acc_prior <- sum(diag(confmat_prior)) / nrow(test_set)\n",
    "acc_loss_matrix <- sum(diag(confmat_loss_matrix)) / nrow(test_set)\n",
    "acc_weights <- sum(diag(confmat_weights)) / nrow(test_set)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
